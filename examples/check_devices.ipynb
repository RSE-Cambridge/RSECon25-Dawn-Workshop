{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8a87f6-2695-4206-9d2d-df04a7284f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "\n",
    "# \"COMPOSITE\": single device per GPU card.\n",
    "# \"FLAT\" : single device per GPU stack; two devices per GPU card.\n",
    "os.environ[\"ZE_FLAT_DEVICE_HIERARCHY\"] = \"FLAT\"\n",
    "\n",
    "import lightning_xpu\n",
    "import lightning\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2556a64-132f-45da-b199-766d7ecee233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define device types to be considered.\n",
    "device_types = [\"cpu\", \"cuda\", \"mps\", \"xpu\", \"fictional_device\"]\n",
    "\n",
    "# Print information about available device types.\n",
    "print(\"Devices seen by torch:\")\n",
    "for device_type in sorted(device_types):\n",
    "    # Determine number of devices of each type.\n",
    "    try:\n",
    "        device_module = importlib.import_module(f\"torch.{device_type}\")\n",
    "    except ModuleNotFoundError:\n",
    "        device_module = None\n",
    "    n_device = getattr(device_module, \"device_count\", lambda: 0)()\n",
    "    devices = [f\"{device_type}:{idx}\" for idx in range(n_device)]\n",
    "    print(f\"    {device_type}: {devices}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df0c426-a731-4777-bcac-8c257ce98f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightning.pytorch.accelerators import AcceleratorRegistry\n",
    "print(\"Devices seen by lightning:\")\n",
    "for device_type in sorted(AcceleratorRegistry.available_accelerators()):\n",
    "    try:\n",
    "        device = AcceleratorRegistry.get(device_type)\n",
    "    except ModuleNotFoundError:\n",
    "        device = None\n",
    "    devices = (device.get_parallel_devices(device.auto_device_count())\n",
    "               if getattr(device, \"is_available\", lambda: False)() else [])\n",
    "    print(f\"    {device_type}: {devices}\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76186d-fc35-45a1-9b4b-bb17e3b1b7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import random\n",
    "import time\n",
    "# Define device types to be considered.\n",
    "device_types = [\"cpu\", \"cuda\", \"mps\", \"xpu\", \"fictional_device\"]\n",
    "# Number of times to attempt matrix multiplication.\n",
    "n_attempt = 3\n",
    "# Print information about available device types.\n",
    "for device_type in device_types:\n",
    "    # Determine number of devices of each type.\n",
    "    try:\n",
    "        device_module = importlib.import_module(f\"torch.{device_type}\")\n",
    "    except ModuleNotFoundError:\n",
    "        device_module = None\n",
    "    if hasattr(device_module, \"is_available\") and device_module.is_available():\n",
    "        n_device = device_module.device_count()\n",
    "    else:\n",
    "        n_device = 0\n",
    "    print(f\"\\nDevice type: {device_type}\")\n",
    "    print(f\"Number of devices: {n_device}\")\n",
    "    # Test matrix-multiplication time for all devices of current type,\n",
    "    # considering devices in random order.\n",
    "    indices = list(range(n_device))\n",
    "    random.shuffle(indices)\n",
    "    i_dim = 0\n",
    "    while n_device:\n",
    "        dim = 2**i_dim\n",
    "        i_dim += 1\n",
    "        i_attempt = 0\n",
    "        print()\n",
    "        while i_attempt < n_attempt:\n",
    "            i_attempt += 1\n",
    "            for i_device in indices:\n",
    "                device_name = f\"{device_type}:{i_device}\"\n",
    "                if dim > 1024 and \"cpu\" == device_type:\n",
    "                    n_device = 0\n",
    "                    i_attempt = n_attempt + 1\n",
    "                    break\n",
    "                t0 = time.time()\n",
    "                try:\n",
    "                    x=torch.randn((dim, dim), device=torch.device(device_name))\n",
    "                    y=torch.randn((dim, dim), device=torch.device(device_name))\n",
    "                    z=torch.matmul(x,y)\n",
    "                except RuntimeError:\n",
    "                    n_device =0\n",
    "                t1 = time.time()\n",
    "                if n_device:\n",
    "                    print(f\"{device_name}: order = {dim}; \"\n",
    "                            f\"attempt ={i_attempt : 3d}; \"\n",
    "                            f\"time ={(t1 - t0) * 1.e6 : 8.1f} microseconds\")\n",
    "                else:\n",
    "                    print(f\"{device_type}: order = {dim}; out of memory\")\n",
    "                    i_attempt = n_attempt + 1\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5694a-e4f4-45d5-8fc3-3815bd3a6b8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "ai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
